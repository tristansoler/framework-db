{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fc0212c-3e00-4db6-adf7-df9bd209a479",
   "metadata": {},
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "An error occurred (ExpiredToken) when calling the GetObject operation: The provided token has expired.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 14\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m      7\u001b[0m sys\u001b[38;5;241m.\u001b[39margv \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample.py\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--dataflow\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample-flow\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--source-file-path\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdsds/dsdas\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--bucket-prefix\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdsdasds\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     12\u001b[0m ]\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mConfigSetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\x850374\\Projects\\platform\\data_framework\\src\\modules\\config\\core.py:54\u001b[0m, in \u001b[0;36mConfigSetup.__init__\u001b[1;34m(self, parameters)\u001b[0m\n\u001b[0;32m     51\u001b[0m dataflow \u001b[38;5;241m=\u001b[39m parameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataflow\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     52\u001b[0m bucket_prefix \u001b[38;5;241m=\u001b[39m parameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbucket_prefix\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 54\u001b[0m json_config \u001b[38;5;241m=\u001b[39m \u001b[43mConfigSetup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_config_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataflow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataflow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbucket_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbucket_prefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_local\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_local\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_instancia\u001b[38;5;241m.\u001b[39mconfig \u001b[38;5;241m=\u001b[39m ConfigSetup\u001b[38;5;241m.\u001b[39mparse_to_model(model\u001b[38;5;241m=\u001b[39mConfig, parameters\u001b[38;5;241m=\u001b[39mparameters, json_file\u001b[38;5;241m=\u001b[39mjson_config)\n",
      "File \u001b[1;32mc:\\Users\\x850374\\Projects\\platform\\data_framework\\src\\modules\\config\\core.py:82\u001b[0m, in \u001b[0;36mConfigSetup.read_config_file\u001b[1;34m(cls, dataflow, bucket_prefix, is_local)\u001b[0m\n\u001b[0;32m     79\u001b[0m     bucket \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbucket_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_code\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     80\u001b[0m     key_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataflow\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/config/transformations.json\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 82\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43ms3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBucket\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbucket\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mKey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m     config_json \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(json\u001b[38;5;241m.\u001b[39mloads(response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBody\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mread()))\n\u001b[0;32m     86\u001b[0m common_flow_json \u001b[38;5;241m=\u001b[39m current_flow_json \u001b[38;5;241m=\u001b[39m config_json\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcommon\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Program Files\\Python312\\Lib\\site-packages\\botocore\\client.py:565\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    561\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    562\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    563\u001b[0m     )\n\u001b[0;32m    564\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[1;32m--> 565\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Program Files\\Python312\\Lib\\site-packages\\botocore\\client.py:1017\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[1;34m(self, operation_name, api_params)\u001b[0m\n\u001b[0;32m   1013\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m error_info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQueryErrorCode\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m error_info\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m   1014\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1015\u001b[0m     )\n\u001b[0;32m   1016\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[1;32m-> 1017\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[0;32m   1018\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1019\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[1;31mClientError\u001b[0m: An error occurred (ExpiredToken) when calling the GetObject operation: The provided token has expired."
     ]
    }
   ],
   "source": [
    "from data_framework.modules.utils.logger import logger\n",
    "from data_framework.modules.storage.core_storage import Storage\n",
    "from data_framework.modules.config.core import ConfigSetup\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.argv = [\n",
    "    \"sample.py\",\n",
    "    '--dataflow', 'sample-flow',\n",
    "    '--source-file-path', 'dsds/dsdas',\n",
    "    '--bucket-prefix', 'dsdasds'\n",
    "]\n",
    "\n",
    "print(ConfigSetup())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8274426e-c212-4076-8f08-a580945b8558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merger processes\n",
      "merger landing_to_raw\n",
      "merger incoming_file\n",
      "    set value zipped value zip\n",
      "    set value file_format value csv\n",
      "    set value csv_specs value {'header_position': 0, 'header': True, 'encoding': 'UTF-8', 'delimiter': ';', 'date_located': 'filename', 'date_located_filename': {'regex': '(\\\\d{4})(\\\\d{2})(\\\\d{2})'}}\n",
      "    set value validations value {'validate_extension': True, 'validate_filename': True, 'validate_csv': True, 'validate_columns': True}\n",
      "merger output_file\n",
      "    set value database value funds_raw\n",
      "    set value partitions value {'datadate': True, 'insert_time': False}\n",
      "    set value processing_specifications value {'technology': 'emr', 'hardware': {'ram': 512}, 'spark_configuration': {'default_catalog': True, 'warehouse': 'funds_raw', 'custom_configuration': [{'parameter': '', 'value': ''}]}}\n",
      "{'processes': {'landing_to_raw': {'incoming_file': {'filename_pattern': '^RTPP_REG_ROW_TYPE_DIVIDEND_\\\\d{8}_CORRECTION\\\\.$', 'zipped': 'zip', 'file_format': 'csv', 'csv_specs': {'header_position': 0, 'header': True, 'encoding': 'UTF-8', 'delimiter': ';', 'date_located': 'filename', 'date_located_filename': {'regex': '(\\\\d{4})(\\\\d{2})(\\\\d{2})'}}, 'validations': {'validate_extension': True, 'validate_filename': True, 'validate_csv': True, 'validate_columns': True}}, 'output_file': {'table': 'morningstar_dividend_correction', 'database': 'funds_raw', 'partitions': {'datadate': True, 'insert_time': False}}, 'processing_specifications': {'technology': 'emr', 'hardware': {'ram': 512}, 'spark_configuration': {'default_catalog': True, 'warehouse': 'funds_raw', 'custom_configuration': [{'parameter': '', 'value': ''}]}}}}}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from data_framework.modules.config.core import config, ConfigSetup\n",
    "from data_framework.modules.catalogue.core_catalogue import CoreCatalogue\n",
    "\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "class Test:\n",
    "\n",
    "    @classmethod\n",
    "    def merged_current_dataflow_with_common(cls, current_dataflow: dict, default: dict) -> dict:\n",
    "\n",
    "        merged = current_dataflow.copy()\n",
    "\n",
    "        for key, value in default.items():\n",
    "            if key in merged and isinstance(merged[key], dict) and isinstance(value, dict):\n",
    "                print(f'merger {key}')\n",
    "                merged[key] = cls.merged_current_dataflow_with_common(merged[key], value)\n",
    "            else:\n",
    "                if merged.get(key) == None:\n",
    "                    print(f'    set value {key} value {value}')     \n",
    "                    merged[key] = value\n",
    "\n",
    "        return merged\n",
    "\n",
    "\n",
    "config_json: dict = None\n",
    "local_file = 'morningstar'\n",
    "dataflow = 'dividend_correction'\n",
    "\n",
    "path_config = 'C:\\\\Users\\\\x850374\\\\Projects\\\\platform\\\\data_framework\\\\src\\\\data_framework\\\\tests\\\\resources\\\\configs\\\\morningstar.json'\n",
    "file = open(path_config)\n",
    "config_json = dict(json.loads(file.read()))\n",
    "\n",
    "common_flow_json = config_json.get('default')\n",
    "current_flow_json = config_json.get(dataflow, None)\n",
    "\n",
    "current_flow_json = Test.merged_current_dataflow_with_common(\n",
    "    current_dataflow=current_flow_json,\n",
    "    default=common_flow_json        \n",
    ")\n",
    "\n",
    "print(current_flow_json)\n",
    "\n",
    "sys.argv = [\n",
    "    \"sample.py\",\n",
    "    '--local-file', 'morningstar',\n",
    "    '--dataflow', 'dividend_correction',\n",
    "    '--process', 'landing_to_raw',\n",
    "    '--source-file-path', 'dsds/dsdas',\n",
    "    '--bucket-prefix', 'dsdasds',\n",
    "    #'--file-name', 'sample.zip',\n",
    "    #'--file-date', '2024-10-09',\n",
    "    '--region', 'eu-west-1'\n",
    "]\n",
    "\n",
    "#ConfigSetup()\n",
    "\n",
    "#config().processes.landing_to_raw.output_file\n",
    "\n",
    "#from flows.landing import ProcessingCoordinator\n",
    "\n",
    "#coordinator = ProcessingCoordinator()\n",
    "#coordinator.process()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65ca28a3-ce12-46e0-b9e0-9f7c434f654b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hola\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02e5fef-c19e-4ccb-8810-0f3e105349ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
