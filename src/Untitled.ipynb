{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fc0212c-3e00-4db6-adf7-df9bd209a479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-30 15:25:52 [INFO][landing.py][validate_filename][91] Name of the file RTPP_REG_ROW_TYPE_DIVIDEND_20240710_CORRECTION.ZIP is valid\n",
      "2024-10-30 15:25:52 [ERROR][landing.py][validate_extension][61] Extension of the file RTPP_REG_ROW_TYPE_DIVIDEND_20240710_CORRECTION.ZIP is invalid\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data_framework.modules.utils.logger import logger\n",
    "from data_framework.modules.storage.core_storage import Storage\n",
    "from data_framework.modules.config.core import ConfigSetup\n",
    "from data_framework.dataflow.landing import FileValidator\n",
    "from data_framework.modules.config.core import config, ConfigSetup\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.argv = [\n",
    "    \"sample.py\",\n",
    "    '--local-file', 'morningstar',\n",
    "    '--dataflow', 'dividend_correction',\n",
    "    '--process', 'landing_to_raw',\n",
    "    '--source-file-path', 'morningstar_dividend_correction/inbound/RTPP_REG_ROW_TYPE_DIVIDEND_20240710_CORRECTION.ZIP',\n",
    "    '--bucket-prefix', 'dsdasds',\n",
    "    #'--file-name', 'sample.zip',\n",
    "    #'--file-date', '2024-10-09',\n",
    "    '--region', 'eu-west-1'\n",
    "]\n",
    "\n",
    "ConfigSetup()\n",
    "\n",
    "file_contents = {\n",
    "    'RTPP_REG_ROW_TYPE_DIVIDEND_20240710_CORRECTION.ZIP': {\n",
    "        'content': '',\n",
    "        'validate': True\n",
    "    }\n",
    "}\n",
    "\n",
    "validator = FileValidator(file_contents=file_contents)\n",
    "validator.validate_filename()\n",
    "validator.validate_extension()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8274426e-c212-4076-8f08-a580945b8558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merger processes\n",
      "merger landing_to_raw\n",
      "merger incoming_file\n",
      "    set value zipped value zip\n",
      "    set value file_format value csv\n",
      "    set value csv_specs value {'header_position': 0, 'header': True, 'encoding': 'UTF-8', 'delimiter': ';', 'date_located': 'filename', 'date_located_filename': {'regex': '(\\\\d{4})(\\\\d{2})(\\\\d{2})'}}\n",
      "    set value validations value {'validate_extension': True, 'validate_filename': True, 'validate_csv': True, 'validate_columns': True}\n",
      "merger output_file\n",
      "    set value database value funds_raw\n",
      "    set value partitions value {'datadate': True, 'insert_time': False}\n",
      "    set value processing_specifications value {'technology': 'emr', 'hardware': {'ram': 512}, 'spark_configuration': {'default_catalog': True, 'warehouse': 'funds_raw', 'custom_configuration': [{'parameter': '', 'value': ''}]}}\n",
      "{'processes': {'landing_to_raw': {'incoming_file': {'filename_pattern': '^RTPP_REG_ROW_TYPE_DIVIDEND_\\\\d{8}_CORRECTION\\\\.$', 'zipped': 'zip', 'file_format': 'csv', 'csv_specs': {'header_position': 0, 'header': True, 'encoding': 'UTF-8', 'delimiter': ';', 'date_located': 'filename', 'date_located_filename': {'regex': '(\\\\d{4})(\\\\d{2})(\\\\d{2})'}}, 'validations': {'validate_extension': True, 'validate_filename': True, 'validate_csv': True, 'validate_columns': True}}, 'output_file': {'table': 'morningstar_dividend_correction', 'database': 'funds_raw', 'partitions': {'datadate': True, 'insert_time': False}}, 'processing_specifications': {'technology': 'emr', 'hardware': {'ram': 512}, 'spark_configuration': {'default_catalog': True, 'warehouse': 'funds_raw', 'custom_configuration': [{'parameter': '', 'value': ''}]}}}}}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from data_framework.modules.config.core import config, ConfigSetup\n",
    "from data_framework.modules.catalogue.core_catalogue import CoreCatalogue\n",
    "\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "class Test:\n",
    "\n",
    "    @classmethod\n",
    "    def merged_current_dataflow_with_common(cls, current_dataflow: dict, default: dict) -> dict:\n",
    "\n",
    "        merged = current_dataflow.copy()\n",
    "\n",
    "        for key, value in default.items():\n",
    "            if key in merged and isinstance(merged[key], dict) and isinstance(value, dict):\n",
    "                print(f'merger {key}')\n",
    "                merged[key] = cls.merged_current_dataflow_with_common(merged[key], value)\n",
    "            else:\n",
    "                if merged.get(key) == None:\n",
    "                    print(f'    set value {key} value {value}')     \n",
    "                    merged[key] = value\n",
    "\n",
    "        return merged\n",
    "\n",
    "\n",
    "config_json: dict = None\n",
    "local_file = 'morningstar'\n",
    "dataflow = 'dividend_correction'\n",
    "\n",
    "path_config = 'C:\\\\Users\\\\x850374\\\\Projects\\\\platform\\\\data_framework\\\\src\\\\data_framework\\\\tests\\\\resources\\\\configs\\\\morningstar.json'\n",
    "file = open(path_config)\n",
    "config_json = dict(json.loads(file.read()))\n",
    "\n",
    "common_flow_json = config_json.get('default')\n",
    "current_flow_json = config_json.get(dataflow, None)\n",
    "\n",
    "current_flow_json = Test.merged_current_dataflow_with_common(\n",
    "    current_dataflow=current_flow_json,\n",
    "    default=common_flow_json        \n",
    ")\n",
    "\n",
    "print(current_flow_json)\n",
    "\n",
    "sys.argv = [\n",
    "    \"sample.py\",\n",
    "    '--local-file', 'morningstar',\n",
    "    '--dataflow', 'dividend_correction',\n",
    "    '--process', 'landing_to_raw',\n",
    "    '--source-file-path', 'dsds/dsdas',\n",
    "    '--bucket-prefix', 'dsdasds',\n",
    "    #'--file-name', 'sample.zip',\n",
    "    #'--file-date', '2024-10-09',\n",
    "    '--region', 'eu-west-1'\n",
    "]\n",
    "\n",
    "ConfigSetup()\n",
    "\n",
    "#config().processes.landing_to_raw.output_file\n",
    "\n",
    "#from flows.landing import ProcessingCoordinator\n",
    "\n",
    "#coordinator = ProcessingCoordinator()\n",
    "#coordinator.process()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65ca28a3-ce12-46e0-b9e0-9f7c434f654b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hola\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02e5fef-c19e-4ccb-8810-0f3e105349ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
